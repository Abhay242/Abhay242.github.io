---
layout: homepage
---

## About Me

Inquistive towards the field of Machine Learning and its unnumerable real-world applications.
Currently, I am working as a Research Associate at SPIRE Lab, IISc Bengaluru under the guidance of Dr Prasanta Kumar Ghosh. Graduated from NIT Srinagar in Computer Science & Engineering. At SPIRE lab I am working on problems related to Audio-Visual Speech Synthesis, Accent Conversion and Developing TTS & ASR systems for multiple Indian languages. During my under-graduate studies I have worked on projects related to Computer Vision and NLP.<br>


### [My Resume](https://drive.google.com/file/d/1POoLwvpoQ8u0V5L__tN0Z2ggp-aPEMLC/view?usp=share_link)

## Research Interests

- **Natural Language Processsing :** Speech Systhesis, Speech Recognition, Language Understanding, Voice Conversion and Styling

## Challanges/Workshops
- **[LIMMITS'23](https://sites.google.com/view/syspinttschallenge2023/home)**<br>
    Multi-speaker, Multi-lingual Indic TTS challenge, as part of signal processing grand challenge in ICASSP 2023. (LIVE !!)
- **[Gram Vaani ASR Challenge](https://sites.google.com/view/gramvaaniasrchallenge/home?authuser=0)** <br>
    Gram Vaani ASR Challenge - part of low resource ASR development special session in INTERSPEECH 2022. (Results Declared) 
    
## Publications

- **Gram vaani asr challenge on spontaneous telephone speech recordings in regional variations of hindi**
  <br>
  _Anish Bhanushali, Grant Bridgman, G Deekshitha, Prasanta Ghosh, Pratik Kumar, Saurabh Kumar, Adithya-Raj Kolladath, Nithya Ravi, Aaditeshwar Seth, Ashish Seth, **Abhayjeet Singh**, NS Vrunda, S Umesh, Sathvik Udupa, VS Lodagala, V Durga Prasad_
  <br>
  **Interspeech 2022**
  <br>
  [[PDF](https://www.isca-speech.org/archive/pdfs/interspeech_2022/bhanushali22_interspeech.pdf)]

- **A study on native American English speech recognition by Indian listeners with varying word familiarity level**
  <br>
  _**Abhayjeet Singh**, Achuth Rao MV, Rakesh Vaideeswaran, Chiranjeevi Yarra, Prasanta Kumar Ghosh_
  <br>
  **COCOSDA 2021**
  <br>
  [[PDF](https://arxiv.org/pdf/2112.04151.pdf)]
  
- **Web Interface for estimating articulatory movements in speech production from acoustics and text**
  <br>
  _Sathvik Udupa, Anwesha Roy, **Abhayjeet Singh**, Aravind Illa, Prasanta Kumar Ghosh_
  <br>
  **InterSpeech 2021**
  <br>
  [[PDF](https://www.isca-speech.org/archive/interspeech_2021/udupa21b_interspeech.html)] [[Code](https://github.com/bloodraven66/AAI_PTA_VIZ_Webpage)]

- **Estimating articulatory movements in speech production with transformer networks**
  <br>
  _Sathvik Udupa, Anwesha Roy, **Abhayjeet Singh**, Aravind Illa, Prasanta Kumar Ghosh_
  <br>
  **InterSpeech 2021**.
  <br>
  [[PDF](https://www.isca-speech.org/archive/pdfs/interspeech_2021/udupa21_interspeech.pdf)] [[Code](https://github.com/bloodraven66/aai_pta_transformers)]

- **Attention and Encoder-Decoder based models for transforming articulatory movements at different speaking rates**
  <br>
  _**Abhayjeet Singh**, Aravind Illa and Prasanta Kumar Ghosh_
  <br>
  **InterSpeech 2020**
  <br>
  [[PDF](https://arxiv.org/abs/2006.03107)] [[Code](https://github.com/Abhay242/AstNet)]

- **A comparative study of estimating articulatory movements from phoneme sequences and acoustic features**
  <br>
  _**Abhayjeet Singh**, Aravind Illa and Prasanta Kumar Ghosh_
  <br>
  **ICASSP 2020**
  <br>
  [[PDF](https://ieeexplore.ieee.org/document/9053852)] [[Code](https://github.com/Abhay242/PhonemeToArticulation)]
  
## Current Projects
  - **REcognizing SPeech in INdian languages ([RESPIN](https://respin.iisc.ac.in/))(funded by: Gates Foundation)**
    <br>
    _Advisor: Prof. Prasanta Kumar Ghosh (IISc Bangalore)_
    <br>
    Speech recognition in agriculture and finance for the poor is an initiative predominantly to create resources and make them available as a digital public good in the open source domain to spur research and innovation in speech recognition in nine different Indian languages in the area of agriculture and finance.
    
  - **SYnthesizing SPeech in INdian languages ([SYSPIN](https://syspin.iisc.ac.in/))(funded by: GIZ, Germany)**<br>
    _Advisor: Prof. Prasanta Kumar Ghosh (IISc Bangalore)_
    <br>
    Develop and open source a large corpus and models for text-to-speech (TTS) systems in multiple Indian languages.
    
  - **[Accent Conversion](https://spire.ee.iisc.ac.in/spire/non_nativeSS.php)**<br>
    _Advisor: Prof. Prasanta Kumar Ghosh (IISc Bangalore)_
    <br>
    Conversion of non-native accent to native accent for better recognition of non-native speech.<br>
    [[Publication](https://arxiv.org/pdf/2112.04151.pdf)]
    
  - **[Vaani](http://vaani.iisc.ac.in/) (funded by: Google)** <br>
    _Advisor: Prof. Prasanta Kumar Ghosh (IISc Bangalore)_
    <br>
    Develop and open source a large corpus and models for Automatic Speech Recognition (ASR) systems in multiple Indian languages.
  
## Previous Projects
  
  - **Estimating articulatory movements from phonemes spoken during speech production**<br>
    _Advisor: Prasanta Kumar Ghosh, Aravind Illa (IISc Bengaluru)<br>_
    Predicting articulatory movements from phonemes using Encoder-Decoder models with Attention mechanism for modelling durations between phonemes and respective articulatory movements.<br>
    [[Publication 1](https://ieeexplore.ieee.org/document/9053852)]  [[Publication 2](https://www.isca-speech.org/archive/pdfs/interspeech_2021/udupa21_interspeech.pdf)]  [[Publication 3](https://www.isca-speech.org/archive/interspeech_2021/udupa21b_interspeech.html)]
    
    
  - **ASTNET - Prediction of Articulatory Motion in Speech Production at different rates**<br>
    _Advisor: Prasanta Kumar Ghosh, Aravind Illa (IISc Bengaluru)<br>_
    Prediction of Articulatory Motion at different rates using Encoder Decoder Model and Dynamic Time Warping Algorithm for Alignment. Predicting articulators at varied speaking rates can be used to enhance performance of ASR systems in real-time.<br>
    [[Publication](https://arxiv.org/abs/2006.03107)]
    
  - **Sign Language Recognition using CNN**<br>
    _Advisor: Prof. RN Mir & Ab Rouf Khan (NIT Srinagar, India)<br>_
    Classifying various hand gestures as English language alphabets in real time using Convolutional Neural Networks. [[Code](https://github.com/Abhay242/Sign-Language-Recognition-using-CNN)]
    
  - **Language Identification System**<br>
    _Advisor: Advisor: Prof. Arun Balaji Budru (IIIT Delhi)<br>_
    Detection of various Indian languages using a convolutional recurrent neural network (CRNN).The CRNN model was trained with input as grey scale image of the audioâ€™s spectrogram. [[Code](https://github.com/Abhay242/language-identification-)]
