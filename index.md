---
layout: homepage
---

## About Me

I am a Research Associate at SPIRE Lab, IISC Bengaluru working under the supervision of Dr Prasanta Kumar Ghosh. Graduated from NIT Srinagar in Computer Science & Engineering. At SPIRE lab I am working on problems related to Audio-Visual Speech Synthesis, Accent Conversion and Developing TTS & ASR systems for multiple Indian languages. During my under-graduate studies I have worked on projects related to Computer Vision and NLP.<br>
Inquistive towards the field of Machine Learning and its unnumerable real-world applications.

### [My Resume](https://drive.google.com/file/d/1xe6RG0ePoQZw0CSeFP3hDuCvGKEzob7J/view?usp=sharing)

## Research Interests

- **Natural Language Processsing :** Speech Systhesis, Speech Recognition, Voice Conversion and Styling

## Publications

- ####A study on native American English speech recognition by Indian listeners with varying word familiarity level
  <br>
  _**Abhayjeet Singh**, Achuth Rao MV, Achuth Rao MV, Chiranjeevi Yarra, Prasanta Kumar Ghosh_
  <br>
 **COCOSDA 2021**.
  <br>
  [[PDF](https://arxiv.org/pdf/2112.04151.pdf)]
  
- **Web Interface for estimating articulatory movements in speech production from acoustics and text**
  <br>
  *Sathvik Udupa, Anwesha Roy, **Abhayjeet Singh**, Aravind Illa, Prasanta Kumar Ghosh*
  <br>
  **InterSpeech 2021**.
  <br>
  [[PDF](https://www.isca-speech.org/archive/interspeech_2021/udupa21b_interspeech.html)] [[Code](https://github.com/bloodraven66/AAI_PTA_VIZ_Webpage)]

- **Estimating articulatory movements in speech production with transformer networks**
  <br>
  Sathvik Udupa, Anwesha Roy, **Abhayjeet Singh**, Aravind Illa, Prasanta Kumar Ghosh
  <br>
  **InterSpeech 2021**.
  <br>
  [[PDF](https://www.isca-speech.org/archive/pdfs/interspeech_2021/udupa21_interspeech.pdf)] [[Code](https://github.com/bloodraven66/aai_pta_transformers)]

- **Attention and Encoder-Decoder based models for transforming articulatory movements at different speaking rates**
  <br>
  **Abhayjeet Singh**, Aravind Illa and Prasanta Kumar Ghosh
  <br>
  **InterSpeech 2020**.
  <br>
  [[PDF](https://arxiv.org/abs/2006.03107)] [[Code](https://github.com/Abhay242/AstNet)]

- **A comparative study of estimating articulatory movements from phoneme sequences and acoustic features**
  <br>
  **Abhayjeet Singh**, Aravind Illa and Prasanta Kumar Ghosh
  <br>
  **ICASSP 2020**.
  <br>
  [[PDF](https://ieeexplore.ieee.org/document/9053852)] [[Code](https://github.com/Abhay242/PhonemeToArticulation)]
  
  
  ## Current Projects
  - **REcognizing SPeech in INdian languages ([RESPIN](https://respin.iisc.ac.in/))**
    <br>
    Advisor: Prof. Prasanta Kumar Ghosh (IISc Bangalore)
    <br><br>
    Speech recognition in agriculture and finance for the poor is an initiative predominantly to create resources and make them available as a digital public good in the open source domain to spur research and innovation in speech recognition in nine different Indian languages in the area of agriculture and finance.
    
  - **SYnthesizing SPeech in INdian languages ([SYSPIN](https://syspin.iisc.ac.in/))**<br>
    Advisor: Prof. Prasanta Kumar Ghosh (IISc Bangalore)
    <br><br>
    Develop and open source a large corpus and models for text-to-speech (TTS) systems in multiple Indian languages.
    
  - **[Accent Conversion](https://spire.ee.iisc.ac.in/spire/non_nativeSS.php)**<br>
    Advisor: Prof. Prasanta Kumar Ghosh (IISc Bangalore)
    <br><br>
    Conversion of non-native accent to native accent for better recognition of non-native speech.<br>
    [Publication](https://arxiv.org/pdf/2112.04151.pdf)
  
  ## Previous Projects
  
  - **Estimating articulatory movements from phonemes spoken during speech production**<br>
    Advisor: Prasanta Kumar Ghosh, Aravind Illa (IISc Bengaluru)<br><br>
    Predicting articulatory movements from phonemes using Encoder-Decoder models with Attention mechanism for modelling durations between phonemes and respective articulatory movements.<br>
    [Publication 1](https://ieeexplore.ieee.org/document/9053852) [Publication 2](https://www.isca-speech.org/archive/pdfs/interspeech_2021/udupa21_interspeech.pdf) [Publication 3](https://www.isca-speech.org/archive/interspeech_2021/udupa21b_interspeech.html)
    
    
  - **ASTNET - Prediction of Articulatory Motion in Speech Production at different rates**<br>
    Advisor: Prasanta Kumar Ghosh, Aravind Illa (IISc Bengaluru)<br><br>
    Prediction of Articulatory Motion at different rates using Encoder Decoder Model and Dynamic Time Warping Algorithm for Alignment. Predicting articulators at varied speaking rates can be used to enhance performance of ASR systems in real-time.<br>
    [Publication](https://arxiv.org/abs/2006.03107)
    
  - **Sign Language Recognition using CNN**<br>
    Advisor: Prof. RN Mir & Ab Rouf Khan (NIT Srinagar, India)<br><br>
    Classifying various hand gestures as English language alphabets in real time using Convolutional Neural Networks. [Code](https://github.com/Abhay242/Sign-Language-Recognition-using-CNN)
    
  - **Language Identification System**<br>
    Advisor: Advisor: Prof. Arun Balaji Budru (IIIT Delhi)
    Detection of various Indian languages using a convolutional recurrent neural network (CRNN).The CRNN model was trained with input as grey scale image of the audioâ€™s spectrogram. [Code](https://github.com/Abhay242/language-identification-)
